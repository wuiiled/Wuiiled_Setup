#!/bin/bash

# ================= å…¨å±€é…ç½® =================

# ã€æ ¸å¿ƒã€‘å¼ºåˆ¶ä½¿ç”¨ C è¯­è¨€åŒºåŸŸè®¾ç½®
# ç¡®ä¿ ASCII æ’åºé¡ºåºï¼šTab(9) < Space(32) < * (42) < . (46) < 0 (48) < 1 (49)
export LC_ALL=C

WORK_DIR=$(mktemp -d)
trap "rm -rf ${WORK_DIR}" EXIT

# æ£€æŸ¥å·¥å…·
CHECK_MIHOMO() {
    if ! command -v mihomo &> /dev/null; then
        echo "âš ï¸  æœªæ£€æµ‹åˆ° mihomo å‘½ä»¤ï¼Œè·³è¿‡ .mrs è½¬æ¢ã€‚"
        return 1
    fi
    return 0
}

# ================= æ ¸å¿ƒå·¥å…·å‡½æ•° =================

# 1. å¹¶è¡Œä¸‹è½½
download_files_parallel() {
    local output_file=$1
    shift
    local urls=("$@")
    local temp_map_dir="${WORK_DIR}/dl_map_$$"
    mkdir -p "$temp_map_dir"

    echo "â¬‡ï¸  å¯åŠ¨å¹¶è¡Œä¸‹è½½ [${#urls[@]} ä¸ªæº]..."
    local pids=()
    local i=0
    
    for url in "${urls[@]}"; do
        local temp_out="${temp_map_dir}/${i}.txt"
        (
            if curl -sLf --connect-timeout 15 --retry 3 "$url" > "$temp_out"; then
                [ -n "$(tail -c1 "$temp_out")" ] && echo "" >> "$temp_out"
                echo "   âœ… å®Œæˆ: $(basename "$url")"
            else
                echo "   âŒ å¤±è´¥: $url"
                rm -f "$temp_out"
            fi
        ) &
        pids+=($!)
        ((i++))
    done

    wait "${pids[@]}"
    cat "${temp_map_dir}"/*.txt > "$output_file" 2>/dev/null
    rm -rf "$temp_map_dir"
}

# 2. åŸŸåæ ‡å‡†åŒ– (é€šç”¨)
normalize_domain() {
    tr 'A-Z' 'a-z' | tr -d '\r' \
    | sed -E '
        s/^[[:space:]]*//; s/[[:space:]]*$//;    
        s/[\$#].*//g;                            
        s/^(0\.0\.0\.0|127\.0\.0\.1)[[:space:]]+//g; 
        s/^!.*//; s/^@@//;                       
        s/\|\|//; s/\^//; s/\|//;                
        s/^domain-keyword,//; s/^domain-suffix,//; s/^domain,//; 
        s/^([^,]+).*/\1/;                        
        s/^\+\.//; s/^\.//; s/\.$//              
    ' \
    | grep -vE '(\*|[^a-z0-9._ -]|^[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+$)' \
    | grep -E '^[a-z0-9_]' \
    | awk '/\./ {print $0}'
}

# 3. å…³é”®è¯è¿‡æ»¤
apply_keyword_filter() {
    local keyword_file="scripts/exclude-keyword.txt"
    if [ -f "$keyword_file" ] && [ -s "$keyword_file" ]; then
        echo "ğŸ” åº”ç”¨å…³é”®è¯æ’é™¤..."
        grep -v -f "$keyword_file" "$1" > "$2"
    else
        cp "$1" "$2"
    fi
}

# 4. ã€é€šç”¨ç®—æ³•ã€‘æ™ºèƒ½è¦†ç›–å»é‡ (Tabåˆ†éš”ç¬¦ç‰ˆ)
# é€»è¾‘ï¼š+.domain (Priority 0) è¦†ç›– domain/sub.domain (Priority 1)
optimize_smart_self() {
    local input=$1
    local output=$2

    echo "ğŸ§  æ‰§è¡Œæ™ºèƒ½è¦†ç›–å»é‡ (+. è¦†ç›–å­åŸŸå)..."

    # å‡†å¤‡æ•°æ®ï¼š[åè½¬] \t [ä¼˜å…ˆçº§] \t [åŸå§‹]
    awk -v OFS="\t" '{ 
        original=$0; pure=original; priority=1;
        # ç§»é™¤è¡Œé¦–ç©ºæ ¼
        sub(/^[[:space:]]+/, "", pure);
        
        # è¯†åˆ«é€šé…å‰ç¼€ (+. æˆ– .)
        if (sub(/^\+\./, "", pure) || sub(/^\./, "", pure)) { 
            priority=0; 
        } 
        
        reversed=""; len=length(pure);
        for(i=len;i>=1;i--) reversed=reversed substr(pure,i,1);
        print reversed, priority, original 
    }' "$input" > "${WORK_DIR}/self_algo.txt"

    # æ’åºä¸å»é‡ (Tabæ’åºç¡®ä¿çˆ¶åœ¨å‰)
    sort -t $'\t' "${WORK_DIR}/self_algo.txt" | awk -F "\t" '
    {
        key = $1
        prio = $2
        original = $3

        # æ£€æŸ¥æ˜¯å¦è¢« Buffer (Priority 0 çš„ +.) è¦†ç›–
        is_child_or_equal = (buffered_key != "" && (index(key, buffered_key ".") == 1 || key == buffered_key));

        if (is_child_or_equal && buffered_prio == 0) {
            # è¢«è¦†ç›–ï¼Œä¸¢å¼ƒ
            next
        } else {
            # æœªè¢«è¦†ç›–ï¼Œè¾“å‡ºä¸Šä¸€ä¸ª Buffer
            if (buffered_line != "") print buffered_line

            # æ›´æ–° Buffer
            if (prio == 0) {
                buffered_key = key
                buffered_prio = prio
                buffered_line = original
            } else {
                print original
                buffered_key = ""
                buffered_line = ""
            }
        }
    }
    END {
        if (buffered_line != "") print buffered_line
    }' > "$output"
}

# 5. ã€ADs/Reject ç®—æ³•ã€‘åŒå‘æ™ºèƒ½ç™½åå•è¿‡æ»¤
apply_advanced_whitelist_filter() {
    local block_in=$1
    local allow_in=$2
    local final_out=$3

    echo "ğŸ›¡ï¸  åº”ç”¨åŒå‘ç™½åå•è¿‡æ»¤..."

    # æ­¥éª¤ A: å‡†å¤‡ç™½åå•
    awk -v OFS="\t" '{ 
        key=$0; reversed=""; len=length(key);
        for(i=len;i>=1;i--) reversed=reversed substr(key,i,1);
        print reversed, 1 
    }' "$allow_in" > "${WORK_DIR}/algo_input.txt"

    # æ­¥éª¤ B: å‡†å¤‡é»‘åå•
    awk -v OFS="\t" '{ 
        original=$0; pure=original;
        sub(/^\+\./,"",pure); sub(/^\./,"",pure);
        reversed=""; len=length(pure);
        for(i=len;i>=1;i--) reversed=reversed substr(pure,i,1);
        print reversed, 0, original 
    }' "$block_in" >> "${WORK_DIR}/algo_input.txt"

    # æ­¥éª¤ C: æ’åºä¸è¿‡æ»¤
    sort -t $'\t' "${WORK_DIR}/algo_input.txt" | awk -F "\t" '
    {
        key = $1
        type = $2
        original = $3

        # é€»è¾‘ 1: çˆ¶æ€å­ (Active Root)
        if (active_white_root != "" && index(key, active_white_root ".") == 1) {
            next
        }

        # é€»è¾‘ 2: å­æ€çˆ¶ (Buffer)
        is_child_or_equal = (buffered_key != "" && (index(key, buffered_key ".") == 1 || key == buffered_key));

        if (is_child_or_equal) {
            if (type == 1) {
                # ç™½åå•å‡ºç° -> æ€æ­» Buffer
                buffered_key = ""
                buffered_line = ""
                active_white_root = key
            }
        } else {
            if (buffered_line != "") print buffered_line

            if (type == 1) {
                active_white_root = key
                buffered_key = ""
                buffered_line = ""
            } else {
                buffered_key = key
                buffered_line = original
                active_white_root = "" 
            }
        }
    }
    END {
        if (buffered_line != "") print buffered_line
    }' > "$final_out"
}

# 6. è¾“å‡ºå°è£…
finalize_output() {
    local src=$1
    local dst=$2
    local mode=$3

    sort -u "$src" -o "$src"

    if [ "$mode" == "add_prefix" ]; then
        echo "âœ¨ æ·»åŠ ç»Ÿä¸€å‰ç¼€ (+.)..."
        sed 's/^/+./' "$src" > "${src}.tmp" && mv "${src}.tmp" "$src"
    fi

    local count=$(wc -l < "$src")
    local date=$(date +"%Y-%m-%d %H:%M:%S")
    sed -i "1i # Count: $count\n# Updated: $date" "$src"
    
    if [ -n "$dst" ] && CHECK_MIHOMO; then
        echo "ğŸ”„ è½¬æ¢ä¸º MRS..."
        mihomo convert-ruleset domain text "$src" "$dst"
    fi
    echo "ğŸ“Š å®Œæˆ: $dst (è¡Œæ•°: $count)"
}

# ================= èµ„æºé…ç½® =================

ALLOW_URLS=(
    "https://raw.githubusercontent.com/Cats-Team/AdRules/refs/heads/script/script/allowlist.txt"
    "https://raw.githubusercontent.com/zoonderkins/blahdns/refs/heads/master/hosts/whitelist.txt"
    "https://raw.githubusercontent.com/AdguardTeam/AdGuardSDNSFilter/master/Filters/exceptions.txt"
)

# ================= æ¨¡å—å®šä¹‰ =================

generate_ads() {
    echo "=== ğŸš€ æ¨¡å— 1: ADs è§„åˆ™ (ads-reject) ==="
    local BLOCK_URLS=(
        "https://raw.githubusercontent.com/pmkol/easymosdns/rules/ad_domain_list.txt"
        "https://raw.githubusercontent.com/wuiiled/Wuiiled_Setup/refs/heads/master/scripts/Reject-addon.txt"
        "https://adguardteam.github.io/HostlistsRegistry/assets/filter_1.txt"
        "https://adguardteam.github.io/HostlistsRegistry/assets/filter_3.txt"
        "https://adguardteam.github.io/HostlistsRegistry/assets/filter_4.txt"
        "https://raw.githubusercontent.com/ForestL18/rules-dat/mihomo/geo/classical/pcdn.list"
        "https://raw.githubusercontent.com/ForestL18/rules-dat/refs/heads/mihomo/geo/classical/reject.list"
        "https://a.dove.isdumb.one/pihole.txt"
        "https://raw.githubusercontent.com/limbopro/Adblock4limbo/main/rule/Surge/Adblock4limbo_surge.list"
        "https://raw.githubusercontent.com/Cats-Team/AdRules/main/adrules_domainset.txt"
        "https://raw.githubusercontent.com/Loyalsoldier/v2ray-rules-dat/refs/heads/release/reject-list.txt"
        "https://ruleset.skk.moe/Clash/domainset/reject.txt"
    )

    download_files_parallel "${WORK_DIR}/raw_ads.txt" "${BLOCK_URLS[@]}"
    download_files_parallel "${WORK_DIR}/raw_allow.txt" "${ALLOW_URLS[@]}"

    grep -vE '^\s*@@' "${WORK_DIR}/raw_ads.txt" | normalize_domain | sort -u > "${WORK_DIR}/clean_ads.txt"
    apply_keyword_filter "${WORK_DIR}/clean_ads.txt" "${WORK_DIR}/filter_ads.txt"

    echo "ğŸ“¥ åˆå¹¶æœ¬åœ°ç™½åå•..."
    local_allow="scripts/exclude-keyword.txt"
    if [ -f "$local_allow" ]; then
        grep -vE '^\s*($|#)' "$local_allow" > "${WORK_DIR}/local_allow_clean.txt"
        cat "${WORK_DIR}/raw_allow.txt" "${WORK_DIR}/local_allow_clean.txt" > "${WORK_DIR}/merged_allow_raw.txt"
    else
        cp "${WORK_DIR}/raw_allow.txt" "${WORK_DIR}/merged_allow_raw.txt"
    fi
    cat "${WORK_DIR}/merged_allow_raw.txt" | normalize_domain | sort -u > "${WORK_DIR}/clean_allow.txt"

    optimize_smart_self "${WORK_DIR}/filter_ads.txt" "${WORK_DIR}/opt_ads.txt"
    optimize_smart_self "${WORK_DIR}/clean_allow.txt" "${WORK_DIR}/opt_allow.txt"

    apply_advanced_whitelist_filter "${WORK_DIR}/opt_ads.txt" "${WORK_DIR}/opt_allow.txt" "${WORK_DIR}/final_ads.txt"

    finalize_output "${WORK_DIR}/final_ads.txt" "ADs_merged.mrs" "add_prefix"
    mv "${WORK_DIR}/final_ads.txt" "ADs_merged.txt"
}

generate_ai() {
    echo "=== ğŸš€ æ¨¡å— 2: AI è§„åˆ™ (ais) ==="
    local AI_URLS=(
        "https://github.com/MetaCubeX/meta-rules-dat/raw/meta/geo/geosite/category-ai-!cn.list"
        "https://ruleset.skk.moe/List/non_ip/ai.conf"
        "https://github.com/DustinWin/ruleset_geodata/raw/mihomo-ruleset/ai.list"
        "https://raw.githubusercontent.com/ConnersHua/RuleGo/refs/heads/master/Surge/Ruleset/Extra/AI.list"
    )
    download_files_parallel "${WORK_DIR}/raw_ai.txt" "${AI_URLS[@]}"
    cat "${WORK_DIR}/raw_ai.txt" | normalize_domain | sort -u > "${WORK_DIR}/clean_ai.txt"
    
    optimize_smart_self "${WORK_DIR}/clean_ai.txt" "${WORK_DIR}/opt_ai.txt"
    
    finalize_output "${WORK_DIR}/opt_ai.txt" "AIs_merged.mrs" "add_prefix"
    mv "${WORK_DIR}/opt_ai.txt" "AIs_merged.txt"
}

generate_fakeip() {
    echo "=== ğŸš€ æ¨¡å— 3: Fake IP (fakeip) ==="
    local FAKE_IP_URLS=(
        "https://raw.githubusercontent.com/vernesong/OpenClash/refs/heads/master/luci-app-openclash/root/etc/openclash/custom/openclash_custom_fake_filter.list"
        "https://raw.githubusercontent.com/juewuy/ShellCrash/dev/public/fake_ip_filter.list"
        "https://raw.githubusercontent.com/DustinWin/ruleset_geodata/refs/heads/mihomo-ruleset/fakeip-filter.list"
        "https://raw.githubusercontent.com/wuiiled/Wuiiled_Setup/refs/heads/master/scripts/fake-ip-addon.txt"
        "https://ruleset.skk.moe/Internal/clash_fake_ip_filter.yaml"
    )
    download_files_parallel "${WORK_DIR}/raw_fakeip_dl.txt" "${FAKE_IP_URLS[@]}"
    
    echo "ğŸ§¹ æ¸…æ´—..."
    cat "${WORK_DIR}/raw_fakeip_dl.txt" \
    | grep -vE '^\s*(dns:|fake-ip-filter:)' \
    | sed 's/^\s*-\s*//' \
    | tr -d "\"'\\" \
    | sed 's/^[[:space:]]*//;s/[[:space:]]*$//' \
    | grep -vE '^\s*($|#)' \
    | sort -u > "${WORK_DIR}/clean_fakeip.txt"

    optimize_smart_self "${WORK_DIR}/clean_fakeip.txt" "${WORK_DIR}/final_fakeip.txt"

    finalize_output "${WORK_DIR}/final_fakeip.txt" "Fake_IP_Filter_merged.mrs" "none"
    mv "${WORK_DIR}/final_fakeip.txt" "Fake_IP_Filter_merged.txt"
}

generate_reject() {
    echo "=== ğŸš€ æ¨¡å— 4: Reject Drop (ads-drop) ==="
    local BLOCK_URLS=(
        "https://ruleset.skk.moe/Clash/non_ip/reject-drop.txt"
        "https://raw.githubusercontent.com/wuiiled/Wuiiled_Setup/master/rules/Custom_Reject-drop.txt"
    )
    download_files_parallel "${WORK_DIR}/raw_rd.txt" "${BLOCK_URLS[@]}"

    echo "ğŸ§¹ SED æ¸…æ´—..."
    cat "${WORK_DIR}/raw_rd.txt" \
    | tr -d '\r' \
    | sed -E '
        /^[[:space:]]*#/d; /skk\.moe/d; /^$/d;
        s/^DOMAIN-SUFFIX,/+./; s/^DOMAIN,//;
        /^\+\.$/d; s/^[[:space:]]*//; s/[[:space:]]*$//
    ' | sort -u > "${WORK_DIR}/clean_rd.txt"

    echo "ğŸ“¥ å‡†å¤‡ç™½åå•..."
    local_allow="scripts/exclude-keyword.txt"
    if [ -f "${WORK_DIR}/clean_allow.txt" ]; then
        cp "${WORK_DIR}/clean_allow.txt" "${WORK_DIR}/clean_rd_allow.txt"
    else
        download_files_parallel "${WORK_DIR}/raw_allow_temp.txt" "${ALLOW_URLS[@]}"
        if [ -f "$local_allow" ]; then
            grep -vE '^\s*($|#)' "$local_allow" > "${WORK_DIR}/local_allow_clean.txt"
            cat "${WORK_DIR}/raw_allow_temp.txt" "${WORK_DIR}/local_allow_clean.txt" > "${WORK_DIR}/merged_allow_raw.txt"
        else
            cp "${WORK_DIR}/raw_allow_temp.txt" "${WORK_DIR}/merged_allow_raw.txt"
        fi
        cat "${WORK_DIR}/merged_allow_raw.txt" | normalize_domain | sort -u > "${WORK_DIR}/clean_rd_allow.txt"
    fi

    apply_advanced_whitelist_filter "${WORK_DIR}/clean_rd.txt" "${WORK_DIR}/clean_rd_allow.txt" "${WORK_DIR}/final_rd.txt"

    finalize_output "${WORK_DIR}/final_rd.txt" "Reject_Drop_merged.mrs" "none"
    mv "${WORK_DIR}/final_rd.txt" "Reject_Drop_merged.txt"
}

generate_cn() {
    echo "=== ğŸš€ æ¨¡å— 5: CN è§„åˆ™ (cn) ==="
    
    local CN_URLS_1=(
        "https://static-file-global.353355.xyz/rules/cn-additional-list.txt"
    )
    local CN_URLS_2=(
        "https://ruleset.skk.moe/Clash/non_ip/domestic.txt"
    )

    download_files_parallel "${WORK_DIR}/raw_cn_1.txt" "${CN_URLS_1[@]}"
    download_files_parallel "${WORK_DIR}/raw_cn_2.txt" "${CN_URLS_2[@]}"

    echo "ğŸ“Š List 1 åŸå§‹è¡Œæ•°: $(wc -l < "${WORK_DIR}/raw_cn_1.txt")"
    echo "ğŸ“Š List 2 åŸå§‹è¡Œæ•°: $(wc -l < "${WORK_DIR}/raw_cn_2.txt")"

    echo "ğŸ§¹ æ¸…æ´— List 1 (çº¯åŸŸå)..."
    # ä¸¥æ ¼æ¸…æ´—æµæ°´çº¿ï¼šè½¬å°å†™ -> å»æ³¨é‡Š -> å»ç©ºæ ¼ -> å»ç©ºè¡Œ -> å»IP -> æ’åºå»é‡
    cat "${WORK_DIR}/raw_cn_1.txt" \
    | tr 'A-Z' 'a-z' \
    | tr -d '\r' \
    | sed 's/#.*//g' \
    | sed 's/^[[:space:]]*//;s/[[:space:]]*$//' \
    | sed '/^$/d' \
    | grep -vE '^[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+$' \
    | sort -u \
    > "${WORK_DIR}/clean_cn_1_base.txt"
    
    echo "ğŸ“Š List 1 çº¯å‡€å»é‡åè¡Œæ•°: $(wc -l < "${WORK_DIR}/clean_cn_1_base.txt")"
    
    # ç»Ÿä¸€åŠ å‰ç¼€
    sed 's/^/+./' "${WORK_DIR}/clean_cn_1_base.txt" > "${WORK_DIR}/clean_cn_1.txt"

    echo "ğŸ§¹ æ¸…æ´— List 2 (Clashæ ¼å¼)..."
    cat "${WORK_DIR}/raw_cn_2.txt" \
    | tr 'A-Z' 'a-z' \
    | tr -d '\r' \
    | grep -v "skk\.moe" \
    | sed '/^[[:space:]]*#/d; /^$/d' \
    | grep -E '^(domain-suffix|domain),' \
    | sed -E 's/^domain-suffix,[[:space:]]*/+./; s/^domain,[[:space:]]*//' \
    | sed 's/^[[:space:]]*//; s/[[:space:]]*$//' \
    | sed '/^$/d' \
    > "${WORK_DIR}/clean_cn_2.txt"
    
    echo "ğŸ“Š List 2 æ¸…æ´—åè¡Œæ•°: $(wc -l < "${WORK_DIR}/clean_cn_2.txt")"

    cat "${WORK_DIR}/clean_cn_1.txt" "${WORK_DIR}/clean_cn_2.txt" > "${WORK_DIR}/merged_cn_raw.txt"
    echo "ğŸ“Š åˆå¹¶åæ€»è¡Œæ•°: $(wc -l < "${WORK_DIR}/merged_cn_raw.txt")"

    optimize_smart_self "${WORK_DIR}/merged_cn_raw.txt" "${WORK_DIR}/final_cn.txt"
    echo "ğŸ“Š æ™ºèƒ½å»é‡åæœ€ç»ˆè¡Œæ•°: $(wc -l < "${WORK_DIR}/final_cn.txt")"

    finalize_output "${WORK_DIR}/final_cn.txt" "CN_merged.mrs" "none"
    mv "${WORK_DIR}/final_cn.txt" "CN_merged.txt"
}

# ================= ä¸»ç¨‹åºå…¥å£ =================

main() {
    local target=${1:-all}
    case "$target" in
        ads-reject) generate_ads ;;    
        ais)        generate_ai ;;
        fakeip)     generate_fakeip ;;
        ads-drop)   generate_reject ;; 
        cn)         generate_cn ;;
        all)
            generate_ads
            generate_ai
            generate_fakeip
            generate_reject
            generate_cn
            ;;
        *)
            echo "ç”¨æ³•: $0 [ads-reject|ais|fakeip|ads-drop|cn|all]"
            exit 1
            ;;
    esac
}

main "$@"
