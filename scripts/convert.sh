#!/bin/bash
# å‡½æ•°ï¼šç”Ÿæˆ ADs_merged.txt
generate_ads_merged() {
    # æœ€ç»ˆè¾“å‡ºæ–‡ä»¶
    OUTPUT_FILE="ADs_merged.txt"

    # ä¸´æ—¶å·¥ä½œç›®å½•
    WORK_DIR=$(mktemp -d)
    trap "rm -rf ${WORK_DIR}" EXIT

    # æ‹¦æˆªè§„åˆ™æº (Blocklist URLs)
    BLOCK_URLS=(
        "https://raw.githubusercontent.com/pmkol/easymosdns/rules/ad_domain_list.txt"
        "https://raw.githubusercontent.com/wuiiled/Wuiiled_Setup/refs/heads/master/rules/Custom_Reject.txt"
        "https://adrules.top/adrules_domainset.txt"
        "https://adguardteam.github.io/HostlistsRegistry/assets/filter_1.txt"
        "https://adguardteam.github.io/HostlistsRegistry/assets/filter_3.txt"
        "https://adguardteam.github.io/HostlistsRegistry/assets/filter_4.txt"
        "https://raw.githubusercontent.com/TG-Twilight/AWAvenue-Ads-Rule/main/Filters/AWAvenue-Ads-Rule-Surge-RULE-SET.list"
        "https://raw.githubusercontent.com/ForestL18/rules-dat/mihomo/geo/classical/pcdn.list"
        "https://raw.githubusercontent.com/ForestL18/rules-dat/refs/heads/mihomo/geo/classical/reject.list"
        "https://a.dove.isdumb.one/pihole.txt"
    )

    # ç™½åå•æº (Allowlist URLs)
    ALLOW_URLS=(
        "https://raw.githubusercontent.com/Cats-Team/AdRules/refs/heads/script/script/allowlist.txt"
        "https://raw.githubusercontent.com/mawenjian/china-cdn-domain-whitelist/refs/heads/master/china-cdn-domain-whitelist.txt"
        "https://raw.githubusercontent.com/zoonderkins/blahdns/refs/heads/master/hosts/whitelist.txt"
    )

    # ================= åŠŸèƒ½å‡½æ•° =================

    download_files() {
        local output_file=$1
        shift
        local urls=("$@")
        
        for url in "${urls[@]}"; do
            echo "â¬‡ï¸  æ­£åœ¨ä¸‹è½½: $url"
            curl -sL --connect-timeout 15 --retry 3 "$url" >> "$output_file"
            echo "" >> "$output_file"
        done
    }

    # ä¸“é—¨ç”¨äºæ¸…æ´—åŸŸåçš„å‡½æ•°
    normalize_domain() {
        # 1. dos2unix
        # 2. ç§»é™¤è¡Œå°¾æ³¨é‡Š ($ æˆ– # åé¢çš„å†…å®¹)
        # 3. ç§»é™¤è¡Œé¦–çš„ 0.0.0.0 æˆ– 127.0.0.1 (é’ˆå¯¹ Hosts æ ¼å¼)
        # 4. ç§»é™¤ DOMAIN-SUFFIX, DOMAIN-KEYWORD, DOMAIN, ç­‰å‰ç¼€
        # 5. ç§»é™¤ || å’Œ ^ (AdGuard æ ¼å¼)
        # 6. å¦‚æœæœ‰é€—å·åˆ†éš” (Surgeæ ¼å¼)ï¼Œåªå–ç¬¬ä¸€éƒ¨åˆ†
        # 7. è½¬å°å†™
        # 8. ç§»é™¤å¼€å¤´ç»“å°¾ç©ºæ ¼
        # 9. åªä¿ç•™åŒ…å«ç‚¹çš„è¡Œ (è¿‡æ»¤çº¯å•è¯)
        
        tr -d '\r' \
        | sed 's/[\$#].*//g' \
        | sed -E 's/^(0\.0\.0\.0|127\.0\.0\.1)[[:space:]]+//g' \
        | sed 's/DOMAIN-SUFFIX,//g; s/DOMAIN-KEYWORD,//g; s/DOMAIN,//g' \
        | sed 's/||//g; s/\^//g' \
        | awk -F, '{print $1}' \
        | tr 'A-Z' 'a-z' \
        | sed 's/^[[:space:]]*//;s/[[:space:]]*$//' \
        | awk '/\./ {print $0}'
    }

    process_blocklist() {
        local input_file=$1
        local output_block=$2
        local output_allow_extra=$3

        echo "ğŸ§¹ æ­£åœ¨å¤„ç†æ‹¦æˆªè§„åˆ™ (åˆ†ç¦» @@ ç™½åå• å’Œ Hosts æ ¼å¼)..."

        # 1. æå– @@ å¼€å¤´çš„è¡Œ (AdBlock ç™½åå•)ï¼Œæ¸…æ´—åå­˜å…¥é¢å¤–ç™½åå•æ–‡ä»¶
        grep "^@@" "$input_file" | sed 's/^@@//g' | normalize_domain > "$output_allow_extra"

        # 2. æå–é @@ å¼€å¤´çš„è¡Œï¼Œè¿›è¡Œæ¸…æ´—
        grep -v "^@@" "$input_file" | grep -v "DOMAIN-KEYWORD" | normalize_domain | sort -u > "$output_block"
    }

    optimize_list() {
        local input_file=$1
        local output_file=$2

        echo "ğŸ§  æ­£åœ¨å»é‡ (ä¸»åŸŸåè‡ªåŠ¨è¦†ç›–å­åŸŸå)..."
        # åè½¬ -> æ’åº -> awkå»é‡ -> åè½¬å›
        cat "$input_file" \
        | rev | sort | awk 'NR==1 {prev=$0; print; next} {if (index($0, prev ".") != 1) {print; prev=$0}}' | rev | sort > "$output_file"
    }

    advanced_whitelist_filter() {
        local block_file=$1
        local allow_file=$2
        local final_file=$3

        echo "ğŸ›¡ï¸  æ­£åœ¨æ‰§è¡Œé«˜çº§ç™½åå•è¿‡æ»¤ (å¦‚æœç™½åå•åŒ…å«ä¸»åŸŸåï¼Œåˆ™ç§»é™¤æ‹¦æˆªåˆ—è¡¨ä¸­çš„å­åŸŸå)..."

        # ç®—æ³•è¯´æ˜ï¼š
        # æˆ‘ä»¬åˆ©ç”¨ ASCII æ’åºç‰¹æ€§ã€‚
        # 1. å‡†å¤‡ç™½åå•ï¼šåè½¬å­—ç¬¦ä¸²ï¼Œå¹¶åœ¨æœ«å°¾åŠ  '!' (ASCII 33, æ¯” '.' 46 å°)ã€‚
        # 2. å‡†å¤‡é»‘åå•ï¼šåè½¬å­—ç¬¦ä¸²ã€‚
        # 3. æ··åˆæ’åºã€‚
        # 4. éå†ï¼šå› ä¸º '!' æ’åœ¨ '.' å‰é¢ï¼Œå¦‚æœç™½åå•æ˜¯ "moc.diub!"ï¼Œå®ƒä¼šæ’åœ¨é»‘åå• "moc.diub.da" å‰é¢ã€‚
        #    awk åªè¦è®°å½•å½“å‰çš„ç™½åå•æ ¹ï¼Œå°±èƒ½è¿‡æ»¤æ‰åé¢åŒ¹é…çš„é»‘åå•é¡¹ã€‚

        # å‡†å¤‡ç™½åå•ï¼šåè½¬å¹¶åŠ æ ‡è®° !
        cat "$allow_file" | rev | sed 's/$/!/' > "${WORK_DIR}/allow_rev_tagged.txt"

        # å‡†å¤‡é»‘åå•ï¼šåè½¬
        cat "$block_file" | rev > "${WORK_DIR}/block_rev.txt"

        # åˆå¹¶ã€æ’åºã€è¿‡æ»¤
        cat "${WORK_DIR}/allow_rev_tagged.txt" "${WORK_DIR}/block_rev.txt" \
        | sort \
        | awk '
            # å¦‚æœè¡Œä»¥ ! ç»“å°¾ï¼Œè¯´æ˜æ˜¯ç™½åå•è§„åˆ™
            /\!$/ {
                # å»æ‰ ! ä¿å­˜ä¸ºå½“å‰ç™½åå•æ ¹
                root = substr($0, 1, length($0)-1);
                next; 
            }
            # å¤„ç†é»‘åå•è¡Œ
            {
                # æ£€æŸ¥1: æ˜¯å¦å®Œå…¨ç›¸ç­‰ (é»‘åå• example.com vs ç™½åå• example.com)
                if ($0 == root) next;
                
                # æ£€æŸ¥2: æ˜¯å¦æ˜¯å­åŸŸå (é»‘åå• a.example.com åŒ¹é… root + ".")
                # index è¿”å›åŒ¹é…ä½ç½®ï¼Œå¿…é¡»æ˜¯ 1 (å³å¼€å¤´åŒ¹é…)
                if (root != "" && index($0, root ".") == 1) next;

                # å¦‚æœæ²¡è¢«ç™½åå•å‘½ä¸­ï¼Œæ‰“å°å‡ºæ¥
                print;
            }
        ' \
        | rev > "$final_file" # åè½¬å›æ¥
    }

    # ================= ä¸»ç¨‹åºæµç¨‹ =================

    echo "=== è„šæœ¬å¼€å§‹è¿è¡Œ ==="

    # 1. ä¸‹è½½åŸå§‹æ–‡ä»¶
    download_files "${WORK_DIR}/raw_block_all.txt" "${BLOCK_URLS[@]}"
    download_files "${WORK_DIR}/raw_allow_all.txt" "${ALLOW_URLS[@]}"

    # 2. å¤„ç†æ‹¦æˆªè§„åˆ™ (æ¸…æ´— + åˆ†ç¦»å‡º @@ è§„åˆ™)
    #    åˆ†ç¦»å‡ºçš„è§„åˆ™ä¼šè¿½åŠ åˆ° raw_allow_extra.txt
    process_blocklist "${WORK_DIR}/raw_block_all.txt" "${WORK_DIR}/clean_block.txt" "${WORK_DIR}/raw_allow_extra.txt"

    # 3. åˆå¹¶æ‰€æœ‰ç™½åå• (åŸå§‹ç™½åå• + ä»æ‹¦æˆªåˆ—è¡¨ä¸­æå–çš„ @@ è§„åˆ™)
    cat "${WORK_DIR}/raw_allow_all.txt" "${WORK_DIR}/raw_allow_extra.txt" | normalize_domain | sort -u > "${WORK_DIR}/clean_allow.txt"

    # 4. ä¼˜åŒ–åˆ—è¡¨ (è‡ªæˆ‘å»é‡ï¼šå¦‚æœæœ‰äº† google.comï¼Œå»æ‰ ad.google.com)
    #    å…ˆå¯¹è‡ªå·±ä¼˜åŒ–ï¼Œå‡å°‘æ•°æ®é‡
    optimize_list "${WORK_DIR}/clean_block.txt" "${WORK_DIR}/opt_block.txt"
    optimize_list "${WORK_DIR}/clean_allow.txt" "${WORK_DIR}/opt_allow.txt"

    # 5. æœ€ç»ˆè¿‡æ»¤ï¼šåº”ç”¨ç™½åå•å‰”é™¤é»‘åå• (åŒ…å«å­åŸŸåé€»è¾‘)
    advanced_whitelist_filter "${WORK_DIR}/opt_block.txt" "${WORK_DIR}/opt_allow.txt" "$OUTPUT_FILE"

    # 6. æœ€ç»ˆæ’åº
    sort -o "$OUTPUT_FILE" "$OUTPUT_FILE"

    # ç»Ÿè®¡
    COUNT=$(wc -l < "$OUTPUT_FILE")
    echo "âœ… ä»»åŠ¡å®Œæˆï¼"
    echo "ğŸ“‚ è¾“å‡ºæ–‡ä»¶: $OUTPUT_FILE"
    echo "ğŸ“Š æœ€ç»ˆè§„åˆ™è¡Œæ•°: $COUNT"

    mihomo convert-ruleset domain text ADs_merged.txt ADs_merged.mrs

    # Surge compatible
    sed -i 's/+./DOMAIN-SUFFIX,/g' ADs_merged.txt

    # æ·»åŠ è®¡æ•°å’Œæ—¶é—´æˆ³
    count=$(wc -l <ADs_merged.txt)
    current_date=$(date +"%Y-%m-%d %H:%M:%S")
    temp_file=$(mktemp)
    echo "# Count: $count, Updated: $current_date" >"$temp_file"
    cat ADs_merged.txt >>"$temp_file"
    mv "$temp_file" ADs_merged.txt
  }

# å‡½æ•°ï¼šç”Ÿæˆ AIs_merged.txt
generate_ais_merged() {
  # ä¸‹è½½å¹¶åˆå¹¶è§„åˆ™
  #curl -skL https://github.com/ForestL18/rules-dat/raw/mihomo/geo/domain/ai-domain.list >>ai.txt
  #echo "" >>ai.txt
  curl -skL https://github.com/MetaCubeX/meta-rules-dat/raw/meta/geo/geosite/category-ai-!cn.list >>ai.txt
  echo "" >>ai.txt
  curl -skL https://ruleset.skk.moe/List/non_ip/ai.conf | sed 's/^DOMAIN,//g' | sed 's/^DOMAIN-SUFFIX,//g' | sed '/^#/d' >>ai.txt
  echo "" >>ai.txt
  curl -skL https://github.com/DustinWin/ruleset_geodata/raw/mihomo-ruleset/ai.list >>ai.txt
  echo "" >>ai.txt
  curl -skL https://raw.githubusercontent.com/ConnersHua/RuleGo/refs/heads/master/Surge/Ruleset/Extra/AI.list | sed 's/^DOMAIN,//g' | sed 's/^DOMAIN-SUFFIX,//g' | sed '/^#/d' >>ai.txt

  # ç§»é™¤æ³¨é‡Šå’Œç©ºè¡Œ
  cat ai.txt | sed '/^#/d' >combined_raw.txt

  # æ ‡å‡†åŒ–åŸŸå
  sed -E 's/^[\+\*\.]+//g' combined_raw.txt | grep -v '^$' >normalized.txt

  # æ’åºå¹¶å»é‡
  sort normalized.txt | uniq >unique_domains.txt

  # å…³é”®è¯æ–‡ä»¶è¿‡æ»¤
  grep -v -f "scripts/exclude-keyword.txt" unique_domains.txt >filtered_domains.txt

  # å¤„ç†åŸŸåï¼šæ·»åŠ  +. å‰ç¼€ï¼ˆDOMAIN-KEYWORD, å’Œ DOMAIN, é™¤å¤–ï¼‰
  awk '{
      if ($0 ~ /^DOMAIN-KEYWORD,/ || $0 ~ /^DOMAIN,/) {
          print $0
      } else {
          print "+." $0
      }
  }' filtered_domains.txt >AIs_merged.txt

  mihomo convert-ruleset domain text AIs_merged.txt AIs_merged.mrs

  # Surge compatible
  sed -i 's/+./DOMAIN-SUFFIX,/g' AIs_merged.txt

  # æ·»åŠ è®¡æ•°å’Œæ—¶é—´æˆ³
  count=$(wc -l <AIs_merged.txt)
  current_date=$(date +"%Y-%m-%d %H:%M:%S")
  temp_file=$(mktemp)
  echo "# Count: $count, Updated: $current_date" >"$temp_file"
  cat AIs_merged.txt >>"$temp_file"
  mv "$temp_file" AIs_merged.txt
}

# å‡½æ•°ï¼šç”Ÿæˆ Fake_IP_Fliter_merged.txt
generate_Fake_IP_Fliter_merged() {
  # ä¸‹è½½å¹¶åˆå¹¶è§„åˆ™
  echo "" >>Fake_IP_Fliter.txt
  curl -skL https://raw.githubusercontent.com/vernesong/OpenClash/refs/heads/master/luci-app-openclash/root/etc/openclash/custom/openclash_custom_fake_filter.list >>Fake_IP_Fliter.txt
  echo "" >>Fake_IP_Fliter.txt
  curl -skL https://raw.githubusercontent.com/juewuy/ShellCrash/dev/public/fake_ip_filter.list >>Fake_IP_Fliter.txt
  echo "" >>Fake_IP_Fliter.txt
  curl -skL https://raw.githubusercontent.com/DustinWin/ruleset_geodata/refs/heads/mihomo-ruleset/fakeip-filter.list >>Fake_IP_Fliter.txt
  echo "" >>Fake_IP_Fliter.txt
  curl -skL https://raw.githubusercontent.com/wuiiled/Wuiiled_Setup/refs/heads/master/scripts/fake-ip-addon.txt >>Fake_IP_Fliter.txt

  # ç§»é™¤æ³¨é‡Šå’Œç©ºè¡Œ
  #cat Fake_IP_Fliter.txt | sed '/^[#!]/d' >Fake_IP_Fliter_combined_raw.txt

  # ç§»é™¤æ³¨é‡Šå’Œç©ºè¡Œå¹¶æ ‡å‡†åŒ–åŸŸå
  #sed -E 's/^[\+\*\.]+//g' Fake_IP_Fliter_combined_raw.txt | grep -v '^$' | tr '[:upper:]' '[:lower:]' | sed 's/[[:space:]]*$//' > Fake_IP_Fliter_normalized.txt
  tr -d '\r' < Fake_IP_Fliter.txt | sed -E '/^[[:space:]]*(#|$)/d; s/^[[:space:]]+//; s/[[:space:]]+$//' > Fake_IP_Fliter_combined_clean.txt

  # æ’åºå¹¶å»é‡
  sort Fake_IP_Fliter_combined_clean.txt | uniq >Fake_IP_Fliter_merged.txt

  # å¤„ç†åŸŸåï¼šæ·»åŠ  +. å‰ç¼€ï¼ˆDOMAIN-KEYWORD é™¤å¤–ï¼‰
  #awk '{
  #    if ($0 ~ /^DOMAIN-KEYWORD/) {
  #        print $0
  #    } else {
  #        print "+." $0
  #    }
  #}' Fake_IP_Fliter_domains.txt >Fake_IP_Fliter_merged.txt

  mihomo convert-ruleset domain text Fake_IP_Fliter_merged.txt Fake_IP_Fliter_merged.mrs

  # Surge compatible
  #sed -i 's/+./DOMAIN-SUFFIX,/g' Fake_IP_Fliter_merged.txt

  # æ·»åŠ è®¡æ•°å’Œæ—¶é—´æˆ³
  count=$(wc -l <Fake_IP_Fliter_merged.txt)
  current_date=$(date +"%Y-%m-%d %H:%M:%S")
  temp_file=$(mktemp)
  echo "# Count: $count, Updated: $current_date" >"$temp_file"
  cat Fake_IP_Fliter_merged.txt >>"$temp_file"
  mv "$temp_file" Fake_IP_Fliter_merged.txt
}

# ä¸»å‡½æ•°
main() {
  if [ "$1" == "ads" ]; then
    generate_ads_merged
  elif [ "$1" == "ais" ]; then
    generate_ais_merged
  elif [ "$1" == "fakeip" ]; then
    generate_Fake_IP_Fliter_merged
  else
    echo "Usage: $0 [ads|ais|fakeip]"
    exit 1
  fi
}

# è°ƒç”¨ä¸»å‡½æ•°
main "$@"
