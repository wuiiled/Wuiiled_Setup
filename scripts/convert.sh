#!/bin/bash

# ================= å…¨å±€é…ç½®ä¸è¾…åŠ©å‡½æ•° =================

# ä¸´æ—¶å·¥ä½œç›®å½• (å…¨å±€ç»Ÿä¸€ç®¡ç†)
WORK_DIR=$(mktemp -d)
trap "rm -rf ${WORK_DIR}" EXIT

# æ£€æŸ¥ mihomo æ˜¯å¦å®‰è£…
CHECK_MIHOMO() {
    if ! command -v mihomo &> /dev/null; then
        echo "âš ï¸  æœªæ£€æµ‹åˆ° mihomo å‘½ä»¤ï¼Œå°†è·³è¿‡ .mrs æ ¼å¼è½¬æ¢ã€‚"
        return 1
    fi
    return 0
}

# ä¸‹è½½å‡½æ•°
download_files() {
    local output_file=$1
    shift
    local urls=("$@")
    
    for url in "${urls[@]}"; do
        echo "â¬‡ï¸  æ­£åœ¨ä¸‹è½½: $url"
        curl -sL --connect-timeout 15 --retry 3 "$url" >> "$output_file"
        echo "" >> "$output_file"
    done
}

# æ ¸å¿ƒæ¸…æ´—å‡½æ•°
normalize_domain() {
    tr 'A-Z' 'a-z' | tr -d '\r' \
    | sed 's/[\$#].*//g' \
    | sed -E 's/^(0\.0\.0\.0|127\.0\.0\.1)[[:space:]]+//g' \
    | sed 's/||//g; s/\^//g' \
    | sed 's/domain-keyword,//g' \
    | sed -E 's/^[[:space:]]*//' \
    | sed 's/^domain-suffix,//g' \
    | sed 's/^domain,//g' \
    | awk -F, '{print $1}' \
    | sed 's/^[[:space:]]*//;s/[[:space:]]*$//' \
    | grep -v "*" \
    | grep -v "[^a-z0-9.-]" \
    | grep -vE '^[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+$' \
    | grep -E '^[a-z0-9]' \
    | grep -E '[a-z0-9]$' \
    | awk '/\./ {print $0}'
}

# æ™ºèƒ½å»é‡å‡½æ•°
optimize_list() {
    local input_file=$1
    local output_file=$2

    echo "ğŸ§  æ­£åœ¨æ™ºèƒ½å»é‡ (ä¸»åŸŸåè¦†ç›–å­åŸŸå)..."
    cat "$input_file" \
    | rev | sort | awk 'NR==1 {prev=$0; print; next} {if (index($0, prev ".") != 1) {print; prev=$0}}' | rev | sort > "$output_file"
}

# å…³é”®è¯è¿‡æ»¤å‡½æ•° (é€šç”¨)
apply_keyword_filter() {
    local input_file=$1
    local output_file=$2
    local keyword_file="scripts/exclude-keyword.txt"

    if [ -f "$keyword_file" ]; then
        echo "ğŸ” åº”ç”¨æœ¬åœ°å…³é”®è¯æ’é™¤ ($keyword_file)..."
        # ä½¿ç”¨ grep -v -f å‰”é™¤åŒ…å«å…³é”®è¯çš„è¡Œ
        grep -v -f "$keyword_file" "$input_file" > "$output_file"
    else
        # æ–‡ä»¶ä¸å­˜åœ¨åˆ™ç›´æ¥å¤åˆ¶
        cp "$input_file" "$output_file"
    fi
}

# æ·»åŠ æœ€ç»ˆå‰ç¼€ (+.)
add_final_prefix() {
    local input_file=$1
    local output_file=$2
    echo "âœ¨ æ­£åœ¨æ·»åŠ æœ€ç»ˆå‰ç¼€ (+.)..."
    sed 's/^/+./' "$input_file" > "$output_file"
}

# æ·»åŠ æ–‡ä»¶å¤´ä¿¡æ¯
add_header_info() {
    local file=$1
    local count=$(wc -l < "$file")
    local current_date=$(date +"%Y-%m-%d %H:%M:%S")
    local temp_header=$(mktemp)
    
    echo "# Count: $count" > "$temp_header"
    echo "# Updated: $current_date" >> "$temp_header"
    cat "$file" >> "$temp_header"
    mv "$temp_header" "$file"
    echo "ğŸ“Š æœ€ç»ˆè¡Œæ•°: $count"
}

# è½¬æ¢ä¸º MRS æ ¼å¼
convert_to_mrs() {
    local src=$1
    local dst=$2
    if CHECK_MIHOMO; then
        echo "ğŸ”„ æ­£åœ¨è½¬æ¢ä¸º binary (.mrs) æ ¼å¼..."
        mihomo convert-ruleset domain text "$src" "$dst"
    fi
}

# ================= æ¨¡å— 1: ADs (å»å¹¿å‘Š) =================

generate_ads_merged() {
    echo "=== å¼€å§‹ç”Ÿæˆ ADs è§„åˆ™ ==="
    OUTPUT_FILE="ADs_merged.txt"

    BLOCK_URLS=(
        "https://raw.githubusercontent.com/pmkol/easymosdns/rules/ad_domain_list.txt"
        "https://raw.githubusercontent.com/wuiiled/Wuiiled_Setup/refs/heads/master/rules/Custom_Reject.txt"
        "https://adrules.top/adrules_domainset.txt"
        "https://adguardteam.github.io/HostlistsRegistry/assets/filter_1.txt"
        "https://adguardteam.github.io/HostlistsRegistry/assets/filter_3.txt"
        "https://adguardteam.github.io/HostlistsRegistry/assets/filter_4.txt"
        "https://raw.githubusercontent.com/TG-Twilight/AWAvenue-Ads-Rule/main/Filters/AWAvenue-Ads-Rule-Surge-RULE-SET.list"
        "https://raw.githubusercontent.com/ForestL18/rules-dat/mihomo/geo/classical/pcdn.list"
        "https://raw.githubusercontent.com/ForestL18/rules-dat/refs/heads/mihomo/geo/classical/reject.list"
        "https://a.dove.isdumb.one/pihole.txt"
    )

    ALLOW_URLS=(
        "https://raw.githubusercontent.com/Cats-Team/AdRules/refs/heads/script/script/allowlist.txt"
        "https://raw.githubusercontent.com/mawenjian/china-cdn-domain-whitelist/refs/heads/master/china-cdn-domain-whitelist.txt"
        "https://raw.githubusercontent.com/zoonderkins/blahdns/refs/heads/master/hosts/whitelist.txt"
    )

    # 1. ä¸‹è½½
    download_files "${WORK_DIR}/raw_block_all.txt" "${BLOCK_URLS[@]}"
    download_files "${WORK_DIR}/raw_allow_all.txt" "${ALLOW_URLS[@]}"

    # 2. å¤„ç†æ‹¦æˆªè§„åˆ™
    echo "ğŸ§¹ å¤„ç†æ‹¦æˆªè§„åˆ™..."
    # æå– @@ ç™½åå•
    grep "^@@" "${WORK_DIR}/raw_block_all.txt" | sed 's/^@@//g' | normalize_domain > "${WORK_DIR}/raw_allow_extra.txt"
    # æå–é»‘åå•
    grep -v "^@@" "${WORK_DIR}/raw_block_all.txt" | normalize_domain | sort -u > "${WORK_DIR}/clean_block.txt"

    # ã€æ–°å¢åŠŸèƒ½ã€‘åœ¨æ¨¡å— 1 åº”ç”¨ exclude-keyword.txt è¿‡æ»¤
    apply_keyword_filter "${WORK_DIR}/clean_block.txt" "${WORK_DIR}/filtered_block.txt"

    # 3. å¤„ç†ç™½åå•
    echo "ğŸ§¹ å¤„ç†ç™½åå•..."
    cat "${WORK_DIR}/raw_allow_all.txt" "${WORK_DIR}/raw_allow_extra.txt" | normalize_domain | sort -u > "${WORK_DIR}/clean_allow.txt"

    # 4. æ™ºèƒ½å»é‡ (æ³¨æ„ï¼šè¿™é‡Œä½¿ç”¨çš„æ˜¯è¿‡æ»¤å…³é”®è¯åçš„ filtered_block.txt)
    optimize_list "${WORK_DIR}/filtered_block.txt" "${WORK_DIR}/opt_block.txt"
    optimize_list "${WORK_DIR}/clean_allow.txt" "${WORK_DIR}/opt_allow.txt"

    # 5. ç™½åå•è¿‡æ»¤ (Apply Allowlist)
    echo "ğŸ›¡ï¸  æ­£åœ¨åº”ç”¨ç™½åå•è¿‡æ»¤..."
    cat "${WORK_DIR}/opt_allow.txt" | rev | sed 's/$/!/' > "${WORK_DIR}/allow_rev_tagged.txt"
    cat "${WORK_DIR}/opt_block.txt" | rev > "${WORK_DIR}/block_rev.txt"

    cat "${WORK_DIR}/allow_rev_tagged.txt" "${WORK_DIR}/block_rev.txt" \
    | sort \
    | awk '/!$/ { root = substr($0, 1, length($0)-1); next; } { if ($0 == root) next; if (root != "" && index($0, root ".") == 1) next; print; }' \
    | rev > "${WORK_DIR}/final_pure.txt"

    # 6. ç”Ÿæˆæœ€ç»ˆæ–‡ä»¶
    add_final_prefix "${WORK_DIR}/final_pure.txt" "$OUTPUT_FILE"
    
    # 7. è½¬æ¢ä¸ç»Ÿè®¡
    convert_to_mrs "$OUTPUT_FILE" "ADs_merged.mrs"
    add_header_info "$OUTPUT_FILE"
    echo "âœ… ADs è§„åˆ™ç”Ÿæˆå®Œæˆã€‚"
}

# ================= æ¨¡å— 2: AI (äººå·¥æ™ºèƒ½) =================

generate_ais_merged() {
    echo "=== å¼€å§‹ç”Ÿæˆ AI è§„åˆ™ ==="
    OUTPUT_FILE="AIs_merged.txt"

    AI_URLS=(
        "https://github.com/MetaCubeX/meta-rules-dat/raw/meta/geo/geosite/category-ai-!cn.list"
        "https://ruleset.skk.moe/List/non_ip/ai.conf"
        "https://github.com/DustinWin/ruleset_geodata/raw/mihomo-ruleset/ai.list"
        "https://raw.githubusercontent.com/ConnersHua/RuleGo/refs/heads/master/Surge/Ruleset/Extra/AI.list"
    )

    # 1. ä¸‹è½½
    download_files "${WORK_DIR}/raw_ai.txt" "${AI_URLS[@]}"

    # 2. æ¸…æ´—
    cat "${WORK_DIR}/raw_ai.txt" | normalize_domain | sort -u > "${WORK_DIR}/clean_ai.txt"

    # ã€å˜æ›´ã€‘ï¼šè¿™é‡Œä¸å†åº”ç”¨å…³é”®è¯è¿‡æ»¤ï¼Œç›´æ¥è¿›å…¥å»é‡æ­¥éª¤

    # 3. æ™ºèƒ½å»é‡
    optimize_list "${WORK_DIR}/clean_ai.txt" "${WORK_DIR}/opt_ai.txt"

    # 4. ç”Ÿæˆæœ€ç»ˆæ–‡ä»¶
    add_final_prefix "${WORK_DIR}/opt_ai.txt" "$OUTPUT_FILE"

    # 5. è½¬æ¢ä¸ç»Ÿè®¡
    convert_to_mrs "$OUTPUT_FILE" "AIs_merged.mrs"
    add_header_info "$OUTPUT_FILE"
    echo "âœ… AI è§„åˆ™ç”Ÿæˆå®Œæˆã€‚"
}

# ================= æ¨¡å— 3: Fake IP Filter =================

generate_Fake_IP_Filter_merged() {
    echo "=== å¼€å§‹ç”Ÿæˆ Fake IP Filter è§„åˆ™ ==="
    OUTPUT_FILE="Fake_IP_Filter_merged.txt"

    FAKE_IP_URLS=(
        "https://raw.githubusercontent.com/vernesong/OpenClash/refs/heads/master/luci-app-openclash/root/etc/openclash/custom/openclash_custom_fake_filter.list"
        "https://raw.githubusercontent.com/juewuy/ShellCrash/dev/public/fake_ip_filter.list"
        "https://raw.githubusercontent.com/DustinWin/ruleset_geodata/refs/heads/mihomo-ruleset/fakeip-filter.list"
        "https://raw.githubusercontent.com/wuiiled/Wuiiled_Setup/refs/heads/master/scripts/fake-ip-addon.txt"
    )

    # 1. ä¸‹è½½
    download_files "${WORK_DIR}/raw_fakeip.txt" "${FAKE_IP_URLS[@]}"

    # 2. æ¸…æ´—
    cat "${WORK_DIR}/raw_fakeip.txt" | normalize_domain | sort -u > "${WORK_DIR}/clean_fakeip.txt"

    # 3. ç”Ÿæˆæœ€ç»ˆæ–‡ä»¶ (ä¸åº”ç”¨è¿‡æ»¤ï¼Œä¹Ÿä¸è¿›è¡Œæ·±åº¦å­åŸŸååˆå¹¶ï¼Œä»¥å…è¯¯ä¼¤ FakeIP ç™½åå•é€»è¾‘)
    # å¤§å¤šæ•° Fake IP åˆ—è¡¨å»ºè®®ä¿æŒåŸæ ·ï¼Œæˆ–ä»…æ·»åŠ å‰ç¼€
    add_final_prefix "${WORK_DIR}/clean_fakeip.txt" "$OUTPUT_FILE"

    # 4. è½¬æ¢ä¸ç»Ÿè®¡
    convert_to_mrs "$OUTPUT_FILE" "Fake_IP_Filter_merged.mrs"
    add_header_info "$OUTPUT_FILE"
    echo "âœ… Fake IP è§„åˆ™ç”Ÿæˆå®Œæˆã€‚"
}

# ================= ä¸»ç¨‹åºå…¥å£ =================

main() {
    case "$1" in
        ads)
            generate_ads_merged
            ;;
        ais)
            generate_ais_merged
            ;;
        fakeip)
            generate_Fake_IP_Filter_merged
            ;;
        all)
            generate_ads_merged
            generate_ais_merged
            generate_Fake_IP_Filter_merged
            ;;
        *)
            echo "ç”¨æ³•: $0 [ads|ais|fakeip|all]"
            exit 1
            ;;
    esac
}

# æ‰§è¡Œä¸»å‡½æ•°
main "$@"
