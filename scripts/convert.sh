#!/bin/bash

# ================= å…¨å±€é…ç½® =================

# ã€æ ¸å¿ƒã€‘å¼ºåˆ¶ä½¿ç”¨ C è¯­è¨€åŒºåŸŸè®¾ç½®
# ç¡®ä¿ ASCII æ’åºé¡ºåºï¼šSpace(32) < . (46) < 0 (48) < 1 (49)
# æ’åºç»“æœï¼šçˆ¶åŸŸååœ¨å‰ï¼Œå­åŸŸååœ¨åï¼›åŒåæ—¶é»‘åå•åœ¨å‰ï¼Œç™½åå•åœ¨å
export LC_ALL=C

WORK_DIR=$(mktemp -d)
trap "rm -rf ${WORK_DIR}" EXIT

# æ£€æŸ¥å·¥å…·
CHECK_MIHOMO() {
    if ! command -v mihomo &> /dev/null; then
        echo "âš ï¸  æœªæ£€æµ‹åˆ° mihomo å‘½ä»¤ï¼Œè·³è¿‡ .mrs è½¬æ¢ã€‚"
        return 1
    fi
    return 0
}

# ================= æ ¸å¿ƒå·¥å…·å‡½æ•° =================

# 1. å¹¶è¡Œä¸‹è½½
download_files_parallel() {
    local output_file=$1
    shift
    local urls=("$@")
    local temp_map_dir="${WORK_DIR}/dl_map_$$"
    mkdir -p "$temp_map_dir"

    echo "â¬‡ï¸  å¯åŠ¨å¹¶è¡Œä¸‹è½½ [${#urls[@]} ä¸ªæº]..."
    local pids=()
    local i=0
    
    for url in "${urls[@]}"; do
        local temp_out="${temp_map_dir}/${i}.txt"
        (
            if curl -sLf --connect-timeout 15 --retry 3 "$url" > "$temp_out"; then
                # ğŸ›¡ï¸ ç¡®ä¿æ–‡ä»¶æœ«å°¾æœ‰æ¢è¡Œç¬¦ï¼Œé˜²æ­¢æ‹¼æ¥é”™è¯¯
                [ -n "$(tail -c1 "$temp_out")" ] && echo "" >> "$temp_out"
                echo "   âœ… å®Œæˆ: $(basename "$url")"
            else
                echo "   âŒ å¤±è´¥: $url"
                rm -f "$temp_out"
            fi
        ) &
        pids+=($!)
        ((i++))
    done

    wait "${pids[@]}"
    cat "${temp_map_dir}"/*.txt > "$output_file" 2>/dev/null
    rm -rf "$temp_map_dir"
}

# 2. åŸŸåæ ‡å‡†åŒ– (å·²ä¿®å¤ 53kf é—®é¢˜)
normalize_domain() {
    tr 'A-Z' 'a-z' | tr -d '\r' \
    | sed 's/[\$#].*//g' \
    | sed -E 's/^(0\.0\.0\.0|127\.0\.0\.1)[[:space:]]+//g' \
    | sed 's/^!.*//g' \
    | sed 's/^@@//g' \
    | sed 's/||//g; s/\^//g; s/|//g' \
    | sed 's/domain-keyword,//g' \
    | sed -E 's/^[[:space:]]*//' \
    | sed 's/^domain-suffix,//g' \
    | sed 's/^domain,//g' \
    | awk -F, '{print $1}' \
    | sed 's/^[[:space:]]*//;s/[[:space:]]*$//' \
    | sed 's/^\+\.//g' \
    | sed 's/^\.//g' \
    | sed 's/\.$//' \
    | grep -v "*" \
    | grep -v "[^a-z0-9._-]" \
    | grep -vE '^[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+$' \
    | grep -E '^[a-z0-9_]' \
    | grep -E '[a-z0-9_]$' \
    | awk '/\./ {print $0}'
}
# è¯´æ˜ï¼šå…ˆæ‰§è¡Œ sed å»é™¤ +. å†æ‰§è¡Œ grepï¼Œç¡®ä¿ +.accwww9.53kf.com èƒ½é€šè¿‡æ ¡éªŒã€‚

# 3. è‡ªèº«å»é‡ (ä»…æ’åº)
optimize_self() {
    echo "ğŸ§  æ‰§è¡Œè‡ªèº«ç®€å•å»é‡..."
    sort -u "$1" > "$2"
}

# 4. å…³é”®è¯è¿‡æ»¤ (ä»…ä¿ç•™ grep é€»è¾‘ï¼Œä¸å†å¤„ç†ç™½åå•)
apply_keyword_filter() {
    local keyword_file="scripts/exclude-keyword.txt"
    if [ -f "$keyword_file" ] && [ -s "$keyword_file" ]; then
        echo "ğŸ” åº”ç”¨å…³é”®è¯æ’é™¤..."
        local before=$(wc -l < "$1")
        grep -v -f "$keyword_file" "$1" > "$2"
        local after=$(wc -l < "$2")
        echo "   -> è¿‡æ»¤æ‰äº† $((before - after)) è¡Œè§„åˆ™"
    else
        cp "$1" "$2"
    fi
}

# 5. ã€æ ¸å¿ƒç®—æ³•ã€‘ç²¾å‡†ç™½åå•è¿‡æ»¤
# é€»è¾‘ï¼š
# - ç™½åå•å­åŸŸå (wgo.mmstat.com) -> åˆ é™¤ é»‘åå•çˆ¶åŸŸå (+.mmstat.com) [é˜²è¯¯æ€]
# - ç™½åå•çˆ¶åŸŸå (xhscdn.com) -> ä¿ç•™ é»‘åå•å­åŸŸå (ads.xhscdn.com) [ç²¾å‡†æ‹¦æˆª]
apply_advanced_whitelist_filter() {
    local block_in=$1
    local allow_in=$2
    local final_out=$3

    echo "ğŸ›¡ï¸  åº”ç”¨æ™ºèƒ½ç™½åå•è¿‡æ»¤..."

    # æ­¥éª¤ A: å‡†å¤‡ç™½åå• [åè½¬] [1]
    awk '{ 
        key=$0; reversed=""; len=length(key);
        for(i=len;i>=1;i--) reversed=reversed substr(key,i,1);
        print reversed, 1 
    }' "$allow_in" > "${WORK_DIR}/algo_input.txt"

    # æ­¥éª¤ B: å‡†å¤‡é»‘åå• [åè½¬] [0] [åŸå§‹]
    # æ³¨æ„ï¼šçº¯åŸŸåç”¨äºæ¯”è¾ƒï¼ŒåŸå§‹è¡Œç”¨äºè¾“å‡º
    awk '{ 
        original=$0; pure=original;
        sub(/^\+\./,"",pure); sub(/^\./,"",pure);
        reversed=""; len=length(pure);
        for(i=len;i>=1;i--) reversed=reversed substr(pure,i,1);
        print reversed, 0, original 
    }' "$block_in" >> "${WORK_DIR}/algo_input.txt"

    # æ­¥éª¤ C: æ’åºä¸è¿‡æ»¤
    # æ’åºé¡ºåº: moc.tatsmm (0) -> moc.tatsmm (1) -> moc.tatsmm.zznc (0)
    sort "${WORK_DIR}/algo_input.txt" | awk '
    BEGIN { FS=" "
